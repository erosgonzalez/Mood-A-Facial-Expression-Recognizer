Name of project: Mood to Music: 
Face Recognition Name of team members: Anakareli Gonzalez, Eros Gonzalez-Lopez, Martin Landin 
Class: CST-205 
Date: March 15, 2017 
Link to GitHub repo: https://github.com/CSUMB-SP17-CST205/Project2-Team24.git 
Link to C9: https://ide.c9.io/egonzalezlopez/egonzalezlopez 
Your TA: Samuel

The project process a user image and will redirect the user to a new page with a song embedded to the page. 
The goal was to create an expression detection with open cv, so a user will get instant music depending on their expression they upload. 
I can see this being implemented in music streaming apps. Using the frontal camera of any device, the user would be given music based on 
their current expression. There is no need to spend time searching for music. With more time, implementation of the webcam would have been possible. 
Building better cascades and more cascades for different emotions would have been possible too.

The directory ExpressionDetection is the everything put together. It is the AI folder, just more organized. 
The directory FinalProj2 is he entire project put together. Website and python scripts.

The use must run the app.py in the FinalProj2 directory through their console. Using the python app.py in the console.
A web address will be given. Enter that web address into a browser. Experiment with different picutures. User must have openCV 
and a Google API Python client. These can be installed through terminal. This project was made in Ubuntu. It allowed for easy installation
in required libraries.