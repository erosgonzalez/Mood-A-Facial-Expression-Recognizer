# Mood-A-Facial-Expression-Recognizer

The project process a user image and will redirect the user to a new page with a song embedded to the page. The goal was to create an expression detection with open cv, so a user will get instant music depending on their expression they upload. I can see this being implemented in music streaming apps. Using the frontal camera of any device, the user would be given music based on their current expression. There is no need to spend time searching for music. With more time, implementation of the webcam would have been possible. Building better cascades and more cascades for different emotions would have been possible too.

The directory ExpressionDetection is the everything put together. It is the AI folder, just more organized. The directory FinalProj2 is he entire project put together. Website and python scripts.

The use must run the app.py in the FinalProj2 directory through their console. Using the python app.py in the console. A web address will be given. Enter that web address into a browser. Experiment with different picutures.
